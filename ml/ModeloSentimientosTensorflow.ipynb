{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPNWVGYB5NtzBOfAW1rP1l4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/darwinyusef/cognitiveAgent/blob/master/ml/ModeloSentimientosTensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain langchain-openai"
      ],
      "metadata": {
        "id": "bNqXAMnNeM4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain langchain-openai langchain-community"
      ],
      "metadata": {
        "id": "a6bmEMVLeyoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Datos de entrenamiento básicos\n",
        "# @markdown <a href=\"https://github.com/darwinyusef/cognitiveAgent/tree/master\">Repositorio con Enlaces a Github</a>\n",
        "!git clone https://github.com/darwinyusef/cognitiveAgent.git\n",
        "%cd cognitiveAgent/\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "from cognitiveAgent.data.intention_sentences import intention_sentences\n"
      ],
      "metadata": {
        "id": "ag_hZ1UXegS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "# entrenamiento 2\n",
        "from sklearn.pipeline import make_pipeline\n",
        "# entrenamiento 1\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "j2YiVoFseE_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from cognitiveAgent.data.sentimental import train_texts_sent"
      ],
      "metadata": {
        "id": "FGB4C9-BfNwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNpSwIT3ddQY"
      },
      "outputs": [],
      "source": [
        "# @title Modelo de clasificación de sentimientos (Logistic regression multiclass)\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "train_labels_sent = [\n",
        "    \"positivo\"] * 25 + [\"negativo\"] * 25 + [\"neutral\"] * 19\n",
        "# En este punto definimos el codificador de etiquetas para iniciar con el entrenamiento  para esto usamos el label encoder\n",
        "le_sent = LabelEncoder() # -> sckitlearn\n",
        "y_sent = le_sent.fit_transform(train_labels_sent) # > entran preguntas / etiquetas positivo | negativo | neutral\n",
        "sentiments = le_sent.classes_.tolist()\n",
        "\n",
        "# @markdown La arquitectura de embeddings a nivel de sentimientos nos permite convertir y embalar los datos de entrenamiento en embeddings al generar un entrenamiento basado en vectores el entrenamiento permite correr con más datos y en menor tiempo\n",
        "X_sent = embedding_model.embed_documents(train_texts_sent)\n",
        "X_sent = np.array(X_sent, dtype=np.float32) # Finalizamos con los embeds y obtenemos una matriz de números"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Agregamos el Modelo simple LRMultiClass\n",
        "num_classes = len(sentiments)\n",
        "input_dim = X_sent.shape[1]\n",
        "#print(\"imput dim\", input_dim, X_sent)\n",
        "\n",
        "# Configuramos el modelo a enviar de sentimientos\n",
        "model_sent = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(input_dim,)), #\n",
        "    tf.keras.layers.Dense(num_classes, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model_sent.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-4),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Entrenamiento\n",
        "model_sent.fit(X_sent, y_sent, epochs=20, batch_size=2, verbose=1)\n",
        "\n",
        "# En este punto las prdicciones del entrenamiento no se exportan en archivos para agilidad del recurso\n",
        "def predict_sentiment(text):\n",
        "    vec = embedding_model.embed_documents([text])\n",
        "    vec = np.array(vec, dtype=np.float32)\n",
        "    probs = model_sent.predict(vec) # -> se realiza un proceso de predicción\n",
        "    idx = np.argmax(probs, axis=1)[0]\n",
        "    sentiment = le_sent.inverse_transform([idx])[0]\n",
        "    confidence = float(probs[0, idx])\n",
        "    return sentiment, confidence\n"
      ],
      "metadata": {
        "id": "80d5yOG3doLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Funciones de activación matemáticas\n",
        "![Sofmax](https://c.mql5.com/2/54/all_af.png)"
      ],
      "metadata": {
        "id": "sHolwAXwffu-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Codigo para realizar *test*\n",
        "# fase entrenamiento -> aqui comento varias pruebas para revisar más adelante\n",
        "for pregunta in intention_sentences[:5]:\n",
        "    sentimiento, conf = predict_sentiment(pregunta)\n",
        "    print(f\"Pregunta: {pregunta}\")\n",
        "    print(f\"→ Sentimiento detectado: {sentimiento} (conf={conf:.2f})\\n\")"
      ],
      "metadata": {
        "id": "S0sQl5LRd_Nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Finalización del sentimiento y obtención de la predición\n",
        "# @markdown Este modelo no entrará en la presentación pero queda de apoyo para que vean como intractuan dos modelos de ML dentro de un agente cognitivo\n",
        "\n",
        "# Ejemplo: analizar solo una sola pregunta <--- solo evalua la var...\n",
        "sentimiento, conf = predict_sentiment(pregunta)\n",
        "print(f\"Pregunta: {pregunta}\")\n",
        "print(f\"→ Sentimiento detectado: {sentimiento} (conf={conf:.2f})\")"
      ],
      "metadata": {
        "id": "znWkmJced0n0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "model_sent.save(\"/content/train/sentiemiento_tensorflow.h5\") # guardar en h5\n",
        "# Guardar el LabelEncoder en pkl\n",
        "joblib.dump(le_sent, \"/content/train/label_encoder_sentimientos.pkl\")"
      ],
      "metadata": {
        "id": "nJbUkzHlfpz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ML de intensión no será expuesto en la presentación\n",
        "# Iniciamos otro modelo (Detectar Intensión) este entrenamiento usan otras herramientas más precisas de ml clásico\n",
        "# pero con un etiquetador especifico en sklearn LinearSVC\n",
        "\n",
        "train_texts = intention_sentences  # ya es lista de strings\n",
        "train_labels = [\"definicion\"] * 4 + [\"uso_practico\"] * 4 + [\"ejemplo\"] * 4 + [\"sintaxis\"] * 4 + \\\n",
        "               [\"instalacion\"] * 4 + [\"depuracion\"] * 4 + [\"librerias_recomendadas\"] * 4 + \\\n",
        "               [\"errores_comunes\"] * 4 + [\"ejercicio_practico\"] * 4 + [\"concepto_avanzado\"] * 4 + \\\n",
        "               [\"comparacion\"] * 4 + [\"recursos_aprendizaje\"] * 4 + [\"proyecto_guiado\"] * 4\n",
        "\n",
        "# @markdown  - Dentro de los train_text y train_labels encontramos un listado de preguntas x 4 a nivel de concepto y realiza un vs entre la pregunta de la base de conocimiento y el etiquetado generando un entrenamiento sistematico\n",
        "print(train_texts[12:15])\n",
        "print(train_labels[12:15])"
      ],
      "metadata": {
        "id": "rXoSyINSg-q3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Entrenamiento de intensión usando un clasificador con vectores de soporte\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "# lanzamos las frases y los etiquetados\n",
        "sentences = train_texts[:]\n",
        "labels = train_labels[:]\n",
        "# los enviamos al entrenamiento a través de un TfidfVectorizer y los evaluaamos con una Clasificación de Vectores de Soporte\n",
        "clf = make_pipeline(TfidfVectorizer(), LinearSVC())\n",
        "clf.fit(sentences, labels)\n",
        "intencion_predicha = clf.predict([pregunta])[0]\n",
        "print(intencion_predicha)"
      ],
      "metadata": {
        "id": "PYMMB2m7hBVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Guardamos el pipeline completo en un archivo\n",
        "joblib.dump(clf, \"/content/train/modelo_intencion.pkl\")"
      ],
      "metadata": {
        "id": "bsGDkGejhWDX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}